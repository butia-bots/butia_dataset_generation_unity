{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Statistics for Perception Package Projects\n",
    "This example notebook shows how to use datasetinsights to load synthetic datasets generated from the [Perception package](https://github.com/Unity-Technologies/com.unity.perception) and visualize dataset statistics. It includes statistics and visualizations of the outputs built into the Perception package and should give a good idea of how to use datasetinsights to visualize custom annotations and metrics.\n",
    "\n",
    "## Setup dataset\n",
    "If the dataset was generated locally, point `data_root` below to the path of the dataset. The `GUID` folder suffix should be changed accordingly.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/home/igormaurell/Workspace/athome/unity_datasets/3e1b6176-12e1-41c8-8123-650e5378e142\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unity Simulation [Optional]\n",
    "If the dataset was generated on Unity Simulation, the following cells can be used to download the metrics needed for dataset statistics.\n",
    "\n",
    "Provide the `run-execution-id` which generated the dataset and a valid `access_token` in the following cell. The `access_token` can be generated using the Unity Simulation [CLI](https://github.com/Unity-Technologies/Unity-Simulation-Docs/blob/master/doc/cli.md#usim-inspect-auth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetinsights.io.downloader import UnitySimulationDownloader\n",
    "\n",
    "#run execution id:\n",
    "# run_execution_id = \"xxx\"\n",
    "# #access_token:\n",
    "# access_token = \"xxx\"\n",
    "# #annotation definition id:\n",
    "# annotation_definition_id = \"6716c783-1c0e-44ae-b1b5-7f068454b66e\"\n",
    "# #unity project id\n",
    "# project_id = \"xxx\"\n",
    "# source_uri = f\"usim://{project_id}/{run_execution_id}\"\n",
    "\n",
    "# downloader = UnitySimulationDownloader(access_token=access_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading the dataset metadata for statistics we first download the relevant files from Unity Simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloader.download(source_uri=source_uri, output=data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset metadata\n",
    "Once the dataset metadata is downloaded, it can be loaded for statistics using `datasetinsights.data.simulation`. Annotation and metric definitions are loaded into pandas dataframes using `AnnotationDefinitions` and `MetricDefinitions` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>format</th>\n",
       "      <th>spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f9f22e05-443f-4602-a422-ebe4ea9b55cb</td>\n",
       "      <td>bounding box</td>\n",
       "      <td>Bounding box for each labeled object visible t...</td>\n",
       "      <td>json</td>\n",
       "      <td>[{'label_id': 0, 'label_name': 'ycb_003_cracke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf</td>\n",
       "      <td>instance segmentation</td>\n",
       "      <td>pixel-wise instance segmentation label</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'label_id': 0, 'label_name': 'ycb_003_cracke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                   name  \\\n",
       "0  f9f22e05-443f-4602-a422-ebe4ea9b55cb           bounding box   \n",
       "1  1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf  instance segmentation   \n",
       "\n",
       "                                         description format  \\\n",
       "0  Bounding box for each labeled object visible t...   json   \n",
       "1             pixel-wise instance segmentation label    PNG   \n",
       "\n",
       "                                                spec  \n",
       "0  [{'label_id': 0, 'label_name': 'ycb_003_cracke...  \n",
       "1  [{'label_id': 0, 'label_name': 'ycb_003_cracke...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasetinsights.datasets.unity_perception import AnnotationDefinitions, MetricDefinitions\n",
    "ann_def = AnnotationDefinitions(data_root)\n",
    "ann_def.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>db1b258e-d1d0-41b6-8751-16f601a2e230</td>\n",
       "      <td>scenario_iteration</td>\n",
       "      <td>Iteration information for dataset sequences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14adb394-46c0-47e8-a3f0-99e754483b76</td>\n",
       "      <td>random-seed</td>\n",
       "      <td>The random seed used to initialize the random ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                name  \\\n",
       "0  db1b258e-d1d0-41b6-8751-16f601a2e230  scenario_iteration   \n",
       "1  14adb394-46c0-47e8-a3f0-99e754483b76         random-seed   \n",
       "\n",
       "                                         description  \n",
       "0        Iteration information for dataset sequences  \n",
       "1  The random seed used to initialize the random ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_def = MetricDefinitions(data_root)\n",
    "metric_def.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in Statistics\n",
    "The following tables and charts are supplied by `datasetinsights.data.datasets.statistics.RenderedObjectInfo` on datasets that include the \"rendered object info\" metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No RenderedObjectInfo in this dataset\n"
     ]
    }
   ],
   "source": [
    "from datasetinsights.stats.statistics import RenderedObjectInfo\n",
    "import datasetinsights.datasets.unity_perception.metrics as metrics\n",
    "from datasetinsights.datasets.unity_perception.exceptions import DefinitionIDError\n",
    "from datasetinsights.stats import bar_plot, histogram_plot, rotation_plot\n",
    "\n",
    "max_samples = 1000          # maximum number of samples points used in histogram plots\n",
    "\n",
    "rendered_object_info_definition_id = \"5ba92024-b3b7-41a7-9d3f-c03a6a8ddd01\"\n",
    "roinfo = None\n",
    "try:\n",
    "    roinfo = RenderedObjectInfo(data_root=data_root, def_id=rendered_object_info_definition_id)\n",
    "except DefinitionIDError:\n",
    "    print(\"No RenderedObjectInfo in this dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roinfo is not None:\n",
    "    print(roinfo.num_captures())\n",
    "    roinfo.raw_table.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Object Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roinfo is not None:\n",
    "    total_count = roinfo.total_counts()\n",
    "    display(total_count)\n",
    "    \n",
    "    display(bar_plot(\n",
    "        total_count, \n",
    "        x=\"label_id\", \n",
    "        y=\"count\", \n",
    "        x_title=\"Label Name\",\n",
    "        y_title=\"Count\",\n",
    "        title=\"Total Object Count in Dataset\",\n",
    "        hover_name=\"label_name\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Capture Object Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roinfo is not None:\n",
    "    per_capture_count = roinfo.per_capture_counts()\n",
    "    display(per_capture_count.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roinfo is not None:\n",
    "    display(histogram_plot(\n",
    "        per_capture_count, \n",
    "        x=\"count\",  \n",
    "        x_title=\"Object Counts Per Capture\",\n",
    "        y_title=\"Frequency\",\n",
    "        title=\"Distribution of Object Counts Per Capture\",\n",
    "        max_samples=max_samples\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Visible Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roinfo is not None:\n",
    "    display(histogram_plot(\n",
    "        roinfo.raw_table, \n",
    "        x=\"visible_pixels\",  \n",
    "        x_title=\"Visible Pixels Per Object\",\n",
    "        y_title=\"Frequency\",\n",
    "        title=\"Distribution of Visible Pixels Per Object\",\n",
    "        max_samples=max_samples\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Visualization\n",
    "In the following sections we show how to load annotations from the Captures object and visualize them. Similar code can be used to consume annotations for model training or visualize and train on custom annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unity Simulation [Optional]\n",
    "If the dataset was generated on Unity Simulation, the following cells can be used to download the images, captures and annotations in the dataset. Make sure you have enough disk space to store all files. For example, a dataset with 100K captures requires roughly 300GiB storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloader.download(source_uri=source_uri, output=data_root, include_binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load captures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor</th>\n",
       "      <th>ego</th>\n",
       "      <th>filename</th>\n",
       "      <th>format</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d59d25f9-3522-41a2-876e-3f13a670002f</td>\n",
       "      <td>e5fb3185-46fc-4077-92d0-6ad263222379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': '56f669d3-1517-4cd5-b495-d6fb79056a49'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6a6843b8-1360-4af8-a9d2-d0ed8197f50a</td>\n",
       "      <td>178011e3-47eb-4ec6-9778-dc766e03afa4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': 'f116bb63-409f-44e8-8e84-3b7d4b98661d'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>365cb45e-a0c6-4af2-9c9e-46eea0011f1f</td>\n",
       "      <td>52bda99d-ffd7-4f69-b42e-6a36d8a16881</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': '7c069902-aed7-4caf-a151-a331f0706215'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                           sequence_id  \\\n",
       "0  d59d25f9-3522-41a2-876e-3f13a670002f  e5fb3185-46fc-4077-92d0-6ad263222379   \n",
       "1  6a6843b8-1360-4af8-a9d2-d0ed8197f50a  178011e3-47eb-4ec6-9778-dc766e03afa4   \n",
       "2  365cb45e-a0c6-4af2-9c9e-46eea0011f1f  52bda99d-ffd7-4f69-b42e-6a36d8a16881   \n",
       "\n",
       "   step  timestamp                                             sensor  \\\n",
       "0     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "1     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "2     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "\n",
       "                                                 ego  \\\n",
       "0  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "1  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "2  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "\n",
       "                                            filename format  \\\n",
       "0  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "1  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "2  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "\n",
       "                                         annotations  \n",
       "0  [{'id': '56f669d3-1517-4cd5-b495-d6fb79056a49'...  \n",
       "1  [{'id': 'f116bb63-409f-44e8-8e84-3b7d4b98661d'...  \n",
       "2  [{'id': '7c069902-aed7-4caf-a151-a331f0706215'...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasetinsights.datasets.unity_perception.captures import Captures\n",
    "cap = Captures(data_root)\n",
    "cap.captures.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding Boxes\n",
    "In this section we render 2d bounding boxes on top of the captured images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from PIL import Image\n",
    "\n",
    "from datasetinsights.stats.visualization.plots import plot_bboxes\n",
    "from datasetinsights.datasets.synthetic import SynDetection2D,read_bounding_box_2d\n",
    "\n",
    "bounding_box_definition_id = \"f9f22e05-443f-4602-a422-ebe4ea9b55cb\"\n",
    "dataset = SynDetection2D(data_path=data_root, def_id=bounding_box_definition_id)\n",
    "def draw_bounding_boxes(index):\n",
    "    image, bboxes = dataset[index]\n",
    "    return plot_bboxes(image, bboxes, dataset.label_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a26dd2667ac4f7196bf28e960493db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='index', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.draw_bounding_boxes(index)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "# pick an index and visualize\n",
    "interact(draw_bounding_boxes, index=list(range(len(dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3D Ground Truth Bounding Boxes\n",
    "In this section we render 3d ground truth bounding boxes on top of the captured images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from PIL import Image\n",
    "from datasetinsights.stats.visualization.plots import plot_bboxes3d\n",
    "from datasetinsights.datasets.synthetic import read_bounding_box_3d\n",
    "\n",
    "bounding_box_3d_defintion_id = \"f9f22e05-443f-4602-a422-ebe4ea9b55cb\"\n",
    "def draw_bounding_boxes3d(index):\n",
    "    filename = os.path.join(data_root, box_captures.loc[index, \"filename\"])\n",
    "    annotations = box_captures.loc[index, \"annotation.values\"]\n",
    "    sensor = box_captures.loc[index, \"sensor\"]\n",
    "\n",
    "    if 'camera_intrinsic' in sensor:\n",
    "        projection = np.array(sensor[\"camera_intrinsic\"])\n",
    "    else:\n",
    "        projection = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "\n",
    "    image = Image.open(filename)\n",
    "    boxes = read_bounding_box_3d(annotations)\n",
    "    img_with_boxes = plot_bboxes3d(image, boxes, projection)\n",
    "    img_with_boxes.thumbnail([1024,1024], Image.ANTIALIAS)\n",
    "    display(img_with_boxes)\n",
    "\n",
    "try:\n",
    "    pass\n",
    "    #box_captures = cap.filter(def_id=bounding_box_3d_defintion_id)\n",
    "    #interact(draw_bounding_boxes3d, index=(0, box_captures.shape[0]))\n",
    "except DefinitionIDError:\n",
    "    print(\"No bounding boxes found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Segmentation\n",
    "In this section we render the semantic segmentation images on top of the captured images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No semantic segmentation images found\n"
     ]
    }
   ],
   "source": [
    "def draw_with_segmentation(index, opacity):\n",
    "    filename = os.path.join(data_root, seg_captures.loc[index, \"filename\"])\n",
    "    seg_filename = os.path.join(data_root, seg_captures.loc[index, \"annotation.filename\"])\n",
    "    \n",
    "    image = Image.open(filename)\n",
    "    seg = Image.open(seg_filename)\n",
    "    img_with_seg = Image.blend(image, seg, opacity)\n",
    "    img_with_seg.thumbnail([1024,1024], Image.ANTIALIAS)\n",
    "    display(img_with_seg)\n",
    "    \n",
    "try:\n",
    "    semantic_segmentation_definition_id = \"12f94d8d-5425-4deb-9b21-5e53ad957d66\"\n",
    "    seg_captures = cap.filter(def_id=semantic_segmentation_definition_id)\n",
    "    interact(draw_with_segmentation, index=(0, seg_captures.shape[0]), opacity=(0.0, 1.0))\n",
    "except DefinitionIDError:\n",
    "    print(\"No semantic segmentation images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance Segmentation\n",
    "In this section we render the instance segmentation images on top of the captured images. Image IDs are mapped to an RGBA color value, below the image we include a preview of the mapping between colors and IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d2223cbd5a4fc49e9b7b89657ae8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5000, description='index', max=10000), FloatSlider(value=0.5, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def instance_sorter(instance):\n",
    "    return instance[\"instance_id\"]\n",
    "\n",
    "def draw_with_instance_segmentation(index, opacity):\n",
    "    filename = os.path.join(data_root, inst_caps.loc[index, \"filename\"])\n",
    "    seg_filename = os.path.join(data_root, inst_caps.loc[index, \"annotation.filename\"])\n",
    "\n",
    "    image = Image.open(filename)\n",
    "    seg = Image.open(seg_filename)\n",
    "    img_with_seg = Image.blend(image, seg, opacity)\n",
    "    img_with_seg.thumbnail([1024,1024], Image.ANTIALIAS)\n",
    "    display(img_with_seg)\n",
    "\n",
    "    anns = inst_caps.loc[index, \"annotation.values\"].copy()\n",
    "    anns.sort(key=instance_sorter)\n",
    "\n",
    "    count = min(5, len(anns))\n",
    "    print(\"First {} ID entries:\".format(count))\n",
    "\n",
    "    for i in range(count):\n",
    "        color = anns[i].get(\"color\")\n",
    "        print (\"{} => Color({:>3}, {:>3}, {:>3})\".format(anns[i].get(\"instance_id\"), color.get(\"r\"), color.get(\"g\"), color.get(\"b\")))\n",
    "\n",
    "try:\n",
    "    inst_seg_def_id = \"1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf\"\n",
    "    inst_caps = cap.filter(def_id=inst_seg_def_id)\n",
    "    interact(draw_with_instance_segmentation, index=(0, inst_caps.shape[0]), opacity=(0.0, 1.0))\n",
    "except DefinitionIDError:\n",
    "    print(\"No instance segmentation images found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_captures = cap.filter(bounding_box_definition_id)\n",
    "inst_captures = cap.filter(inst_seg_def_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor</th>\n",
       "      <th>ego</th>\n",
       "      <th>filename</th>\n",
       "      <th>format</th>\n",
       "      <th>annotations</th>\n",
       "      <th>annotation.id</th>\n",
       "      <th>annotation.annotation_definition</th>\n",
       "      <th>annotation.values</th>\n",
       "      <th>annotation.filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d59d25f9-3522-41a2-876e-3f13a670002f</td>\n",
       "      <td>e5fb3185-46fc-4077-92d0-6ad263222379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': '56f669d3-1517-4cd5-b495-d6fb79056a49'...</td>\n",
       "      <td>56f669d3-1517-4cd5-b495-d6fb79056a49</td>\n",
       "      <td>f9f22e05-443f-4602-a422-ebe4ea9b55cb</td>\n",
       "      <td>[{'label_id': 12, 'label_name': 'ycb_004_sugar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6a6843b8-1360-4af8-a9d2-d0ed8197f50a</td>\n",
       "      <td>178011e3-47eb-4ec6-9778-dc766e03afa4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': 'f116bb63-409f-44e8-8e84-3b7d4b98661d'...</td>\n",
       "      <td>f116bb63-409f-44e8-8e84-3b7d4b98661d</td>\n",
       "      <td>f9f22e05-443f-4602-a422-ebe4ea9b55cb</td>\n",
       "      <td>[{'label_id': 13, 'label_name': 'ycb_005_tomat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>365cb45e-a0c6-4af2-9c9e-46eea0011f1f</td>\n",
       "      <td>52bda99d-ffd7-4f69-b42e-6a36d8a16881</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': '7c069902-aed7-4caf-a151-a331f0706215'...</td>\n",
       "      <td>7c069902-aed7-4caf-a151-a331f0706215</td>\n",
       "      <td>f9f22e05-443f-4602-a422-ebe4ea9b55cb</td>\n",
       "      <td>[{'label_id': 0, 'label_name': 'ycb_003_cracke...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48bc69cb-8212-4d8a-bf9f-3ce2efcdf2d2</td>\n",
       "      <td>1953fb6d-bda2-4e74-9add-d664d4bf839a</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': 'b8e270fc-fe17-40eb-9b9c-66ec8e0ae489'...</td>\n",
       "      <td>b8e270fc-fe17-40eb-9b9c-66ec8e0ae489</td>\n",
       "      <td>f9f22e05-443f-4602-a422-ebe4ea9b55cb</td>\n",
       "      <td>[{'label_id': 9, 'label_name': 'ycb_007_tuna_f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02b16a47-4738-4f55-84fb-0af508637e5f</td>\n",
       "      <td>b787623e-bd4f-4b47-99d1-02e3c9c7b268</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': '566fc617-7a40-4dad-bbb0-7f4970cbbdeb'...</td>\n",
       "      <td>566fc617-7a40-4dad-bbb0-7f4970cbbdeb</td>\n",
       "      <td>f9f22e05-443f-4602-a422-ebe4ea9b55cb</td>\n",
       "      <td>[{'label_id': 10, 'label_name': 'ycb_002_maste...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                           sequence_id  \\\n",
       "0  d59d25f9-3522-41a2-876e-3f13a670002f  e5fb3185-46fc-4077-92d0-6ad263222379   \n",
       "1  6a6843b8-1360-4af8-a9d2-d0ed8197f50a  178011e3-47eb-4ec6-9778-dc766e03afa4   \n",
       "2  365cb45e-a0c6-4af2-9c9e-46eea0011f1f  52bda99d-ffd7-4f69-b42e-6a36d8a16881   \n",
       "3  48bc69cb-8212-4d8a-bf9f-3ce2efcdf2d2  1953fb6d-bda2-4e74-9add-d664d4bf839a   \n",
       "4  02b16a47-4738-4f55-84fb-0af508637e5f  b787623e-bd4f-4b47-99d1-02e3c9c7b268   \n",
       "\n",
       "   step  timestamp                                             sensor  \\\n",
       "0     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "1     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "2     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "3     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "4     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "\n",
       "                                                 ego  \\\n",
       "0  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "1  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "2  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "3  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "4  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "\n",
       "                                            filename format  \\\n",
       "0  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "1  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "2  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "3  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "4  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  [{'id': '56f669d3-1517-4cd5-b495-d6fb79056a49'...   \n",
       "1  [{'id': 'f116bb63-409f-44e8-8e84-3b7d4b98661d'...   \n",
       "2  [{'id': '7c069902-aed7-4caf-a151-a331f0706215'...   \n",
       "3  [{'id': 'b8e270fc-fe17-40eb-9b9c-66ec8e0ae489'...   \n",
       "4  [{'id': '566fc617-7a40-4dad-bbb0-7f4970cbbdeb'...   \n",
       "\n",
       "                          annotation.id      annotation.annotation_definition  \\\n",
       "0  56f669d3-1517-4cd5-b495-d6fb79056a49  f9f22e05-443f-4602-a422-ebe4ea9b55cb   \n",
       "1  f116bb63-409f-44e8-8e84-3b7d4b98661d  f9f22e05-443f-4602-a422-ebe4ea9b55cb   \n",
       "2  7c069902-aed7-4caf-a151-a331f0706215  f9f22e05-443f-4602-a422-ebe4ea9b55cb   \n",
       "3  b8e270fc-fe17-40eb-9b9c-66ec8e0ae489  f9f22e05-443f-4602-a422-ebe4ea9b55cb   \n",
       "4  566fc617-7a40-4dad-bbb0-7f4970cbbdeb  f9f22e05-443f-4602-a422-ebe4ea9b55cb   \n",
       "\n",
       "                                   annotation.values annotation.filename  \n",
       "0  [{'label_id': 12, 'label_name': 'ycb_004_sugar...                 NaN  \n",
       "1  [{'label_id': 13, 'label_name': 'ycb_005_tomat...                 NaN  \n",
       "2  [{'label_id': 0, 'label_name': 'ycb_003_cracke...                 NaN  \n",
       "3  [{'label_id': 9, 'label_name': 'ycb_007_tuna_f...                 NaN  \n",
       "4  [{'label_id': 10, 'label_name': 'ycb_002_maste...                 NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_captures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor</th>\n",
       "      <th>ego</th>\n",
       "      <th>filename</th>\n",
       "      <th>format</th>\n",
       "      <th>annotations</th>\n",
       "      <th>annotation.id</th>\n",
       "      <th>annotation.annotation_definition</th>\n",
       "      <th>annotation.values</th>\n",
       "      <th>annotation.filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d59d25f9-3522-41a2-876e-3f13a670002f</td>\n",
       "      <td>e5fb3185-46fc-4077-92d0-6ad263222379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': '56f669d3-1517-4cd5-b495-d6fb79056a49'...</td>\n",
       "      <td>152d93d4-98cb-4dc9-9612-99ddd9b6b2af</td>\n",
       "      <td>1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf</td>\n",
       "      <td>[{'instance_id': 38, 'color': {'r': 255, 'g': ...</td>\n",
       "      <td>InstanceSegmentationb74d83a2-0be7-4b13-89b4-d9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6a6843b8-1360-4af8-a9d2-d0ed8197f50a</td>\n",
       "      <td>178011e3-47eb-4ec6-9778-dc766e03afa4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': 'f116bb63-409f-44e8-8e84-3b7d4b98661d'...</td>\n",
       "      <td>b65206ea-c083-444e-955b-25ce50e5b271</td>\n",
       "      <td>1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf</td>\n",
       "      <td>[{'instance_id': 62, 'color': {'r': 51, 'g': 0...</td>\n",
       "      <td>InstanceSegmentationb74d83a2-0be7-4b13-89b4-d9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>365cb45e-a0c6-4af2-9c9e-46eea0011f1f</td>\n",
       "      <td>52bda99d-ffd7-4f69-b42e-6a36d8a16881</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': '7c069902-aed7-4caf-a151-a331f0706215'...</td>\n",
       "      <td>58963791-fd45-40f1-b8be-3240e689b1c8</td>\n",
       "      <td>1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf</td>\n",
       "      <td>[{'instance_id': 107, 'color': {'r': 240, 'g':...</td>\n",
       "      <td>InstanceSegmentationb74d83a2-0be7-4b13-89b4-d9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48bc69cb-8212-4d8a-bf9f-3ce2efcdf2d2</td>\n",
       "      <td>1953fb6d-bda2-4e74-9add-d664d4bf839a</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': 'b8e270fc-fe17-40eb-9b9c-66ec8e0ae489'...</td>\n",
       "      <td>282050d3-d221-4422-b22a-515f8b4a008c</td>\n",
       "      <td>1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf</td>\n",
       "      <td>[{'instance_id': 36, 'color': {'r': 0, 'g': 54...</td>\n",
       "      <td>InstanceSegmentationb74d83a2-0be7-4b13-89b4-d9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02b16a47-4738-4f55-84fb-0af508637e5f</td>\n",
       "      <td>b787623e-bd4f-4b47-99d1-02e3c9c7b268</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'sensor_id': '27864388-937d-4bce-b657-5d28d37...</td>\n",
       "      <td>{'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...</td>\n",
       "      <td>RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...</td>\n",
       "      <td>PNG</td>\n",
       "      <td>[{'id': '566fc617-7a40-4dad-bbb0-7f4970cbbdeb'...</td>\n",
       "      <td>9761bd40-1202-4fe1-8a4f-a5b7cc603f79</td>\n",
       "      <td>1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf</td>\n",
       "      <td>[{'instance_id': 105, 'color': {'r': 79, 'g': ...</td>\n",
       "      <td>InstanceSegmentationb74d83a2-0be7-4b13-89b4-d9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                           sequence_id  \\\n",
       "0  d59d25f9-3522-41a2-876e-3f13a670002f  e5fb3185-46fc-4077-92d0-6ad263222379   \n",
       "1  6a6843b8-1360-4af8-a9d2-d0ed8197f50a  178011e3-47eb-4ec6-9778-dc766e03afa4   \n",
       "2  365cb45e-a0c6-4af2-9c9e-46eea0011f1f  52bda99d-ffd7-4f69-b42e-6a36d8a16881   \n",
       "3  48bc69cb-8212-4d8a-bf9f-3ce2efcdf2d2  1953fb6d-bda2-4e74-9add-d664d4bf839a   \n",
       "4  02b16a47-4738-4f55-84fb-0af508637e5f  b787623e-bd4f-4b47-99d1-02e3c9c7b268   \n",
       "\n",
       "   step  timestamp                                             sensor  \\\n",
       "0     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "1     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "2     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "3     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "4     0        0.0  {'sensor_id': '27864388-937d-4bce-b657-5d28d37...   \n",
       "\n",
       "                                                 ego  \\\n",
       "0  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "1  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "2  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "3  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "4  {'ego_id': '3ae70021-18dc-4a95-b2a3-f7606b7eaa...   \n",
       "\n",
       "                                            filename format  \\\n",
       "0  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "1  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "2  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "3  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "4  RGB268c3b64-677c-439b-a0d8-fc8c5f393156/rgb_15...    PNG   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  [{'id': '56f669d3-1517-4cd5-b495-d6fb79056a49'...   \n",
       "1  [{'id': 'f116bb63-409f-44e8-8e84-3b7d4b98661d'...   \n",
       "2  [{'id': '7c069902-aed7-4caf-a151-a331f0706215'...   \n",
       "3  [{'id': 'b8e270fc-fe17-40eb-9b9c-66ec8e0ae489'...   \n",
       "4  [{'id': '566fc617-7a40-4dad-bbb0-7f4970cbbdeb'...   \n",
       "\n",
       "                          annotation.id      annotation.annotation_definition  \\\n",
       "0  152d93d4-98cb-4dc9-9612-99ddd9b6b2af  1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf   \n",
       "1  b65206ea-c083-444e-955b-25ce50e5b271  1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf   \n",
       "2  58963791-fd45-40f1-b8be-3240e689b1c8  1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf   \n",
       "3  282050d3-d221-4422-b22a-515f8b4a008c  1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf   \n",
       "4  9761bd40-1202-4fe1-8a4f-a5b7cc603f79  1ccebeb4-5886-41ff-8fe0-f911fa8cbcdf   \n",
       "\n",
       "                                   annotation.values  \\\n",
       "0  [{'instance_id': 38, 'color': {'r': 255, 'g': ...   \n",
       "1  [{'instance_id': 62, 'color': {'r': 51, 'g': 0...   \n",
       "2  [{'instance_id': 107, 'color': {'r': 240, 'g':...   \n",
       "3  [{'instance_id': 36, 'color': {'r': 0, 'g': 54...   \n",
       "4  [{'instance_id': 105, 'color': {'r': 79, 'g': ...   \n",
       "\n",
       "                                 annotation.filename  \n",
       "0  InstanceSegmentationb74d83a2-0be7-4b13-89b4-d9...  \n",
       "1  InstanceSegmentationb74d83a2-0be7-4b13-89b4-d9...  \n",
       "2  InstanceSegmentationb74d83a2-0be7-4b13-89b4-d9...  \n",
       "3  InstanceSegmentationb74d83a2-0be7-4b13-89b4-d9...  \n",
       "4  InstanceSegmentationb74d83a2-0be7-4b13-89b4-d9...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_captures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for image_filename, bbox_ann, inst_ann, inst_mask in zip(bbox_captures['filename'], bbox_captures['annotation.values'], inst_captures['annotation.values'], inst_captures['annotation.filename']):\n",
    "    dataset.append((image_filename, bbox_ann, inst_ann, inst_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9*len(dataset))\n",
    "test_size = len(dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset[:train_size]\n",
    "test_set = dataset[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_coco_annotations(dataset, subset):\n",
    "    coco_dict = {}\n",
    "    coco_dict['info'] = {}\n",
    "    coco_dict['images'] = []\n",
    "    '''coco_dict['categories'] = [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"name\": \"BG\",\n",
    "            \"supercategory\": \"background\"\n",
    "        }\n",
    "    ]'''\n",
    "    coco_dict['categories'] = []\n",
    "    coco_dict['annotations'] = []\n",
    "    labels = {}\n",
    "    for i, (image_filename, bbox_ann, inst_ann, inst_mask) in enumerate(tqdm.tqdm(dataset)):\n",
    "        img = Image.open(os.path.join(data_root, image_filename)).convert(\"RGB\")\n",
    "        mask = Image.open(os.path.join(data_root, inst_mask)).convert(\"RGB\")\n",
    "        img_arr = np.array(img)\n",
    "        mask_arr = np.array(mask)\n",
    "        for j in range(len(bbox_ann)):\n",
    "            if bbox_ann[j]['label_id'] not in labels:\n",
    "                labels[bbox_ann[j]['label_id']] = bbox_ann[j]['label_name']\n",
    "            color = inst_ann[j]['color']\n",
    "            mask_color = np.array([color['r'], color['g'], color['b']])\n",
    "            object_mask = (mask_arr[:,:] == mask_color).all(axis=2)*255\n",
    "            contours, hierarchy = cv2.findContours(object_mask.astype('uint8'), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if len(contours) > 0:\n",
    "                bbox = [\n",
    "                    float(bbox_ann[j]['x']),\n",
    "                    float(bbox_ann[j]['y']),\n",
    "                    float(bbox_ann[j]['width']),\n",
    "                    float(bbox_ann[j]['height']),\n",
    "                ]\n",
    "                annotation = {}\n",
    "                annotation['segmentation'] = [contour.reshape(-1).astype('float64').tolist() for contour in contours]\n",
    "                annotation['area'] = int((np.sum(object_mask)/255)/3)\n",
    "                annotation['iscrowd'] = 0\n",
    "                annotation['bbox'] = bbox\n",
    "                annotation['category_id'] = bbox_ann[j]['label_id']\n",
    "                annotation['image_id'] = i\n",
    "                annotation['id'] = i*len(dataset) + j\n",
    "                coco_dict['annotations'].append(annotation)\n",
    "        coco_dict['images'].append({\n",
    "            'id': i,\n",
    "            'width': img_arr.shape[1],\n",
    "            'height': img_arr.shape[0],\n",
    "            'file_name': image_filename\n",
    "        })\n",
    "    label_list = list(labels.items())\n",
    "    label_list.sort(key=lambda x: x[0])\n",
    "    for label_id, label_name in label_list:\n",
    "        coco_dict['categories'].append({\n",
    "            \"id\": label_id,\n",
    "            \"name\": label_name,\n",
    "            \"supercategory\": \"household_object\"\n",
    "        })\n",
    "    with open(os.path.join(data_root, \"{}.json\".format(subset)), 'w') as f:\n",
    "        json.dump(coco_dict, f, indent=4, sort_keys=True)\n",
    "    print(tuple([v for k, v in label_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [16:38<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ycb_003_cracker_box', 'ycb_009_gelatin_box', 'ycb_008_pudding_box', 'ycb_010_potted_meat_can', 'ycb_006_mustard_bottle', 'ycb_018_plum', 'ycb_016_pear', 'ycb_011_banana', 'ycb_012_strawberry', 'ycb_007_tuna_fish_can', 'ycb_002_master_chef_can', 'ycb_014_lemon', 'ycb_004_sugar_box', 'ycb_005_tomato_soup_can', 'ycb_015_peach', 'ycb_013_apple', 'ycb_017_orange', 'person_standing')\n"
     ]
    }
   ],
   "source": [
    "write_coco_annotations(train_set, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:03<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ycb_003_cracker_box', 'ycb_009_gelatin_box', 'ycb_008_pudding_box', 'ycb_010_potted_meat_can', 'ycb_006_mustard_bottle', 'ycb_018_plum', 'ycb_016_pear', 'ycb_011_banana', 'ycb_012_strawberry', 'ycb_007_tuna_fish_can', 'ycb_002_master_chef_can', 'ycb_014_lemon', 'ycb_004_sugar_box', 'ycb_005_tomato_soup_can', 'ycb_015_peach', 'ycb_013_apple', 'ycb_017_orange', 'person_standing')\n"
     ]
    }
   ],
   "source": [
    "write_coco_annotations(test_set, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(('ycb_003_cracker_box', 'ycb_009_gelatin_box', 'ycb_008_pudding_box', 'ycb_010_potted_meat_can', 'ycb_006_mustard_bottle', 'ycb_018_plum', 'ycb_016_pear', 'ycb_011_banana', 'ycb_012_strawberry', 'ycb_007_tuna_fish_can', 'ycb_002_master_chef_can', 'ycb_014_lemon', 'ycb_004_sugar_box', 'ycb_005_tomato_soup_can', 'ycb_015_peach', 'ycb_013_apple', 'ycb_017_orange', 'person_standing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (('ycb_028_skillet_lid', 'ycb_003_cracker_box', 'ycb_058_golf_ball', 'ycb_009_gelatin_box', 'ycb_073-b_lego_duplo', 'ycb_008_pudding_box', 'ycb_010_potted_meat_can', 'ycb_072-b_toy_airplane', 'ycb_062_dice', 'ycb_024_bowl', 'ycb_059_chain', 'ycb_006_mustard_bottle', 'ycb_018_plum', 'ycb_063-b_marbles', 'ycb_063-a_marbles', 'ycb_065-e_cups', 'ycb_016_pear', 'ycb_065-b_cups', 'ycb_073-c_lego_duplo', 'ycb_043_phillips_screwdriver', 'ycb_052_extra_large_clamp', 'ycb_071_nine_hole_peg_test', 'ycb_065-d_cups', 'ycb_061_foam_brick', 'ycb_025_mug', 'ycb_040_large_marker', 'ycb_065-f_cups', 'ycb_065-c_cups', 'ycb_054_softball', 'ycb_070-a_colored_wood_blocks', 'ycb_029_plate', 'ycb_030_fork', 'ycb_011_banana', 'ycb_072-c_toy_airplane', 'ycb_065-a_cups', 'ycb_035_power_drill', 'ycb_051_large_clamp', 'ycb_012_strawberry', 'ycb_007_tuna_fish_can', 'ycb_057_racquetball', 'ycb_044_flat_screwdriver', 'ycb_002_master_chef_can', 'ycb_048_hammer', 'ycb_072-e_toy_airplane', 'ycb_033_spatula', 'ycb_065-h_cups', 'ycb_073-e_lego_duplo', 'ycb_014_lemon', 'ycb_065-i_cups', 'ycb_050_medium_clamp', 'trofast', 'ycb_022_windex_bottle', 'ycb_053_mini_soccer_ball', 'ycb_004_sugar_box', 'ycb_072-a_toy_airplane', 'ycb_070-b_colored_wood_blocks', 'ycb_005_tomato_soup_can', 'ycb_065-g_cups', 'ycb_015_peach', 'ycb_027_skillet', 'ycb_077_rubiks_cube', 'ycb_013_apple', 'ycb_032_knife', 'ycb_056_tennis_ball', 'ycb_073-d_lego_duplo', 'ycb_038_padlock', 'ycb_019_pitcher_base', 'ycb_073-a_lego_duplo', 'ycb_065-j_cups', 'ycb_072-d_toy_airplane', 'ycb_037_scissors', 'ycb_036_wood_block', 'ycb_026_sponge', 'ycb_031_spoon', 'ycb_055_baseball', 'ycb_017_orange', 'ycb_021_bleach_cleanser', 'ycb_073-f_lego_duplo', 'ycb_042_adjustable_wrench', 'ycb_073-g_lego_duplo'))\n",
    "b = (('person_standing', 'ycb_002_master_chef_can', 'ycb_003_cracker_box', 'ycb_004_sugar_box', 'ycb_005_tomato_soup_can', 'ycb_006_mustard_bottle', 'ycb_007_tuna_fish_can', 'ycb_008_pudding_box', 'ycb_009_gelatin_box', 'ycb_010_potted_meat_can', 'ycb_011_banana', 'ycb_012_strawberry', 'ycb_013_apple', 'ycb_014_lemon', 'ycb_015_peach', 'ycb_016_pear', 'ycb_017_orange', 'ycb_018_plum', 'ycb_019_pitcher_base', 'ycb_021_bleach_cleanser', 'ycb_022_windex_bottle', 'ycb_024_bowl', 'ycb_025_mug', 'ycb_026_sponge', 'ycb_029_plate', 'ycb_030_fork', 'ycb_031_spoon', 'ycb_033_spatula', 'ycb_040_large_marker', 'ycb_051_large_clamp', 'ycb_053_mini_soccer_ball', 'ycb_054_softball', 'ycb_055_baseball', 'ycb_056_tennis_ball', 'ycb_057_racquetball', 'ycb_058_golf_ball', 'ycb_059_chain', 'ycb_061_foam_brick', 'ycb_062_dice', 'ycb_063-a_marbles', 'ycb_063-b_marbles', 'ycb_065-a_cups', 'ycb_065-b_cups', 'ycb_065-c_cups', 'ycb_065-d_cups', 'ycb_065-e_cups', 'ycb_065-f_cups', 'ycb_065-g_cups', 'ycb_065-h_cups', 'ycb_065-i_cups', 'ycb_065-j_cups', 'ycb_070-a_colored_wood_blocks', 'ycb_070-b_colored_wood_blocks', 'ycb_071_nine_hole_peg_test', 'ycb_072-a_toy_airplane', 'ycb_072-b_toy_airplane', 'ycb_072-c_toy_airplane', 'ycb_072-d_toy_airplane', 'ycb_072-e_toy_airplane', 'ycb_073-a_lego_duplo', 'ycb_073-b_lego_duplo', 'ycb_073-c_lego_duplo', 'ycb_073-d_lego_duplo', 'ycb_073-e_lego_duplo', 'ycb_073-f_lego_duplo', 'ycb_073-g_lego_duplo', 'ycb_077_rubiks_cube'))\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
